{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3b4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import numpy as np \n",
    "import torchvision.models as models \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils import * \n",
    "from model import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc43f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Dataset \n",
    "data = np.load('./CompressedDatasets/cifar/dataset.npz')\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a834070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reconstruct_img(x, sigma, Vt) -> torch.Tensor: \n",
    "#     x = x @ (torch.diag(sigma) @  Vt)\n",
    "#     x = x.reshape(32, 32, 3)\n",
    "#     plt.imshow(x)\n",
    "#     x = x.permute(2, 0, 1)\n",
    "#     x = torch.clip(x, 0, 1)\n",
    "#     return x # [N, 3, 32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cd2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.012186701..1.0941331].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.012207017..1.0000138].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U shape: torch.Size([50000, 200]), sigma shape: torch.Size([3072]), V shape: torch.Size([3072, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2cce50e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAALUpJREFUeJzt3XtwXPV5//Hv3nellVY364ZssLnf7PxCieMhoQ64dtwZBoInA01maloGBmqYgpsmdSeBkLYjSmYSkoxj/miKm5mAEzoxDEziBExsT1qb1m493BoPdgy2sSVbkrWSVnvf85vvSaQgsOF5bMlfafV+zZyRV/v4q3PbffbsOfvZgOd5ngEA4BwLnus/CACARQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADgRNtNMpVIxR48eNXV1dSYQCLieHQCAks03GB4eNp2dnSYYDM6cBmSbz9y5c13PBgDgLB0+fNh0dXWd+wa0fv16881vftP09PSYRYsWme9973vmE5/4xEf+P3vkY617+CETj8dFf6tUKovnq1QuGQ3NUVgiHlONHY1G5MXKwKRsLieuHRkeUY2dz8vHtgJTtU6MMcm6pLi2qalRNXZzU5N8PpK1qrEj4ZCqvlQoiGtHhtOqsQcGBsS1fSdOqMY+1tMjrj1+vFc19rBiv80p91kT1L37Eg7Ln0q17+yEgvJ9JRSJqsYOKpYzoKgtFkvmxZ9tG38+P6cN6Mc//rFZu3ateeKJJ8zixYvN448/blasWGH27dtnWltbRRvHNp+Z1oDiygYUi8l3Fm1in6a8WCzqBld2Q1UDiukakHQfsRKJhGrsmpoacW1t7RQ3oIj8oVop67ZnNpudFvt4JBKZsif9cDk8cxtQSL6vhBX7yVQ2IOmyTslFCN/61rfMXXfdZf7iL/7CXHHFFX4jsg/mf/3Xf52KPwcAmIEmvQEVCgWzZ88es2zZsj/8kWDQv71z584P1OfzeTM0NDRhAgBUv0lvQH19faZcLpu2trYJv7e37fmg9+vu7japVGp84gIEAJgdnH8OaN26dSadTo9P9qoJAED1m/SLEFpaWvyTZr29E69osbfb29s/UB+LxfwJADC7TPoRUDQaNddcc43ZunXrhA+X2ttLliyZ7D8HAJihpuQybHsJ9urVq80f/dEf+Z/9sZdhZzIZ/6o4AACmrAHddttt5sSJE+ahhx7yLzz42Mc+ZrZs2fKBCxMAALPXlCUh3Hffff50pgLBkD9JBEPyD0gFVR+LtB+Ok6+iulSDauyGhgbVW5saxZL8A7f26HSqUhYszRpPKM8HNrfI0wra2j78Q9Dv19Euf8Fkr+DUiCj2WSuXkX/q/8SJ46qxj717RFwbUyZVFIryBIdCPq8aO/QhGWPvN5rT7VfBUHDK6gOB4JR97DsU1m0fo/hQbLlUnPQPzju/Cg4AMDvRgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAANUVxXO2CoWiCQqjeIqlsnjcfEEeDWJFI/IIj2SdamgTTcj/Q70y6kWjTrlONDE/qlwOP6JG95oomawR18YSSdXY4WhCXBuP1arGjnrKxBT5YppEfFg3LxF5zFNAEd3iq8gXNKAKnTEmqJiVSCikGzusrFeMb78dQKOgeH4rlXSP5YBiJZYUsUrFouw5giMgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBPTNgsuGo2YaEyYURUsT0mukuUpsq8CYXlunBWJy/PDojW6oDlPkcHlBYuqsY0yOy6bzYprM5lR1dj9A0Pi2mi0TzX2wEBaXNvV2aYaO1Wny6WrlPLi2tFR3TrM5eTbJ5/NqcYuKvaVsjA/bIxXrkzdK21lXlvFyJ8nimXdcuZz8sdnXrsOFTmNgYB8nZSEeZEcAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnJi2UTx1qZRJJBKi2oonj8GIxnUxJSYgX0XxGl28ignKx86M6iJQRkYy4trBQXmcjZVVxrEMDQ2La0eG5PE31uiofDlDAXnsiDW3s11cW8jr4okumNepqk8m5DFP8bjscTOmvq5ePh9J3T6eUMxLNCKM3vq9WFS+TgIlXdyUZ3T7SllRHlDE9ljBoPw4QTeyfe6sTEm8V0W4QjgCAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADgxbbPgwuGYCUfiotpASJGpltVlQuULJXFtWpF5ZmUVY4+M6DLsenqPi2t7e/tUY+eUuWflsjxvqljIq8YuFuTzEgnpkrIKefm+0tjYqBq7taVFVd/c2CCurauVPW7GleX7YX/fCdXQ0jxHv1aZYVcqyrdPqVxWjZ0v6vbDkiIMzgvo9sOw4vktHtMdU5RK8m1fKsofa15ANh8cAQEAnJj0BvT1r3/dBAKBCdNll1022X8GADDDTclbcFdeeaV56aWX/vBHwtP2nT4AgCNT0hlsw2lvl3+XCgBg9pmSc0BvvfWW6ezsNAsWLDBf/OIXzaFDh05bm8/nzdDQ0IQJAFD9Jr0BLV682GzcuNFs2bLFbNiwwRw8eNB8+tOfNsPDp75CrLu726RSqfFp7ty5kz1LAIDZ0IBWrlxpPv/5z5uFCxeaFStWmJ/97GdmcHDQ/OQnPzll/bp160w6nR6fDh8+PNmzBACYhqb86oCGhgZzySWXmP3795/y/lgs5k8AgNllyj8HNDIyYg4cOGA6Ojqm+k8BAGZzA/rSl75ktm/fbt5++23zn//5n+Zzn/ucCYVC5s/+7M8m+08BAGawSX8L7siRI36z6e/vN3PmzDGf+tSnzK5du/x/a4xkMqZUkUW4lD15H333aK9qPvr6B8S1gXBENbYiocb0DQyqxj52TL6cJwd1Vx5GIlFVfbMidiZZW6MaOxwMTVkEykgmK67t6dVF1LS16KJ7Ukl5TE1zQ61q7EhEvt9GlPt40MjXeVAdUSPf9pGw7rX26KgusiuriKcKhnTrMBKVn6KIKrdPKChfL0FP/oQV8Bw1oE2bNk32kACAKkQWHADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwAkaEACgOr+O4Uy9e7THxGJxUW2+JM8oOviO7vuGensUGV9B3eoMKnKbMtm8auyBk2lxbb6gy71qSdar6hub5Vlwba26zMBYWJ4Hlh/NqMYuFuRZcO/89h3V2FFpWNbvhY0ih2tB15SNHQzoXrPGwvLHRG1c97UskZB8HYbDuvWdyZz6CzRPp1iQPz4DIUUIpLFfWSPPXkwkdDmNFWHeppWpaJ4nZOubIyAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBPTNoqnt/eEiURlsRK5ojxOYjA9opoPxdAmEZdFB41pUcTORGM1qrGHM6Pi2myuoBq7obFBVd/R3i6ubW1pUo0d9OQbqK/nmGrswwd7xbXH3hlQjV3M6qJemlO14trz2ptVY9fXRKdkfVuxcEBc26RYRisUrhPXDo3oHpuZEd326e/vF9cW8rpYrYoioiigjDMyiiieSqk06bUcAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcmLZZcPl80VQ8WY5UyZP30dpkvWo+6hpaxLWtiswz64ILLhDXJmp0OVmDaXmW1dCwLh8vGNS9bqlLJsW1yVrdchaz8sy7Ql6Xedff1yeuHejV5cwl4yFVfalYnLJ1WJOQPw2UK2XV2Pl8TlwbUeTGWS0tjeLahgb5PmgNDQ2q6vsU+8rIaFY1tinLt31B8Xiw8kV5vltOMXaJLDgAwHRGAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAODFts+ACgaA/SSQTdeJx61Mx1XzUNTSIazvOO081dmtrq7g2X9DlmI1m5RlcibhunegSu4yJhOSvc4LKwcMh+S4cCuvy1wIB+cxEIhHV2MmkfJ+1mpqb5bUt8vxCK+jlxbUFRSadNTgozyQMB+S5ZNbcrg5x7Zyk/HFsDQ+lVfX5rDzf7aQip9EqluT5e6WKURktKrZ9Qf6cUhLOM0dAAAAn1A1ox44d5qabbjKdnZ3+K8Rnn312wv2e55mHHnrIdHR0mEQiYZYtW2beeuutyZxnAMBsbECZTMYsWrTIrF+//pT3P/bYY+a73/2ueeKJJ8wrr7xiamtrzYoVK0wuJz98AwBUP/U5oJUrV/rTqdijn8cff9x89atfNTfffLP/ux/+8Iemra3NP1K6/fbbz36OAQBVYVLPAR08eND09PT4b7uNSaVSZvHixWbnzp2n/D/5fN4MDQ1NmAAA1W9SG5BtPpY94nkve3vsvvfr7u72m9TYNHfu3MmcJQDANOX8Krh169aZdDo9Ph0+fNj1LAEAZloDam9v93/29vZO+L29PXbf+8ViMVNfXz9hAgBUv0ltQPPnz/cbzdatW8d/Z8/p2KvhlixZMpl/CgAw266CGxkZMfv3759w4cHevXtNU1OTmTdvnnnggQfMP/7jP5qLL77Yb0hf+9rX/M8M3XLLLZM97wCA2dSAdu/ebT7zmc+M3167dq3/c/Xq1Wbjxo3my1/+sv9ZobvvvtsMDg6aT33qU2bLli0mHo+r/k657Jlg2RPVBkPyiJVkMqmajwZFFE9UGccyOHhSXNvbe0I1dl9f/5RF69TX6WJkknH5eomFdQflxYp820eiUdXY4Zh8n00oo3VSimgdq76xSVxrP3unUc7L81uKBV0UTzotv6o1FNCNXS7J61NJXTzRgnldqvpYRP5UOjSsi+IZHMqIa/sGdVcRVyrymJ9cdlRcG/S8qWlAS5cu9T/vczo2HeEb3/iGPwEAMG2vggMAzE40IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBPqKJ5zJZfPmXJFllEVjubF48ZrdHlTeUX+Udqr6MYuyOd7oF+eG2dlhuR5U/YrMTSCdbqssaAibC4Q8HRjKwaX7k9jvIB87JAyZ65U0S1nelie8XUyrdtXwp78MREO654yYjH5eqkUdY9NTTZZqZBVjV0b1y1nW0tKXNvcoMujHM7kxLWxo8dVY5cKBXFtPidfh8ViSVTHERAAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwIlpG8VT8mM5ZFEopZIs9sEaHZXHd1jBYHDKunlNTVxe29GmGrvU0iyuDWiycmxMSVIXxdPU2CCuTaXqVWOHQiFxbUERJWJlFfE3uRF59NGZLKdmHx9KD+nmpVYel9PS0qQae968TnFtJt2nGjsckEcrZYZ08USlki4WKFiRb59EJKIbOyl/nhiuq1GNna6XP5ZHR+URQgWieAAA0xkNCADgBA0IAOAEDQgA4AQNCADgBA0IAOAEDQgA4AQNCADgBA0IAOAEDQgA4AQNCADgxLTNgkulUiYSlWVUpRRZY/GELispEZfXNzfJ58PqaJ8jrk3WJlRjByrelOSM+WMr8vGsljkt4tq2jnbV2DU18iyrrg55LpnV3irfPsODuqyxhpQuT++8dnkWYFz4uBkTDcm3Z4Mya2xOU0pcG/N0WX01Ufl8R4Jl1diBgO4xUSkX5MWebl4iRp532JCMqcbOtcifswrFvLg2X5Bl6XEEBABwggYEAHCCBgQAcIIGBABwggYEAHCCBgQAcIIGBABwggYEAHCCBgQAcIIGBABwYtpG8Vx5+WUmHpfFz7R1niceN5HQRaCEw/IYjMbGetXY7S1N4tpEPKIau1TIiWtzWXmtLxBQlTc1y5ezo7NZNbYmeCRkOlRje2VZnIiVHZXHDVmJmHy/suoS8odquaCIhTHGjJbl0TAjQ2nV2MNpeURRNjOkGrtSK98P6xNJ1dihWl2c0fDwiLg2X9TF/JQV0T0p5XwHw/LHZsXI471yOdk+yBEQAMAJGhAAYGY0oB07dpibbrrJdHZ2mkAgYJ599tkJ999xxx3+7987ffazn53MeQYAzMYGlMlkzKJFi8z69etPW2MbzrFjx8anp59++mznEwAw2y9CWLlypT99mFgsZtrbdd/rAgCYXabkHNC2bdtMa2urufTSS829995r+vv7T1ubz+fN0NDQhAkAUP0mvQHZt99++MMfmq1bt5p//ud/Ntu3b/ePmMqnudSzu7vb//bTsWnu3LmTPUsAgNnwOaDbb799/N9XX321Wbhwobnwwgv9o6Ibb7zxA/Xr1q0za9euHb9tj4BoQgBQ/ab8MuwFCxaYlpYWs3///tOeL6qvr58wAQCq35Q3oCNHjvjngDo6dJ9CBwBUN/VbcCMjIxOOZg4ePGj27t1rmpqa/OmRRx4xq1at8q+CO3DggPnyl79sLrroIrNixYrJnncAwGxqQLt37zaf+cxnxm+Pnb9ZvXq12bBhg3n11VfNv/3bv5nBwUH/w6rLly83//AP/+C/1abx8f/3MVNbK8ttu/iSS8XjJpN1qvkIheQHibUJXUZaIiDPVvJ0Q5tiSZ4fNToyrBrbq8jHtuKJGnFtzOgWtKjJpxrVLWcwIF/OhpQuY7CuNq6qjyrmJah8X6NckmfH5XKjqrGHBk9/Bez7ZU72qcaek5LnI0aVz3SJmC57sVyU/4G8ch2WixVxbSisy4KrT8ryNq02I887HM3mp6YBLV261Hje6R/0v/jFL7RDAgBmIbLgAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAADV8X1Ak6Wzo02c23ZeZ4N43LgiO+x35NlkHxZRdLYCyjC4SCgkrk2lGrQzoytXrPNyuagae2BA/g26Q4MnVWN7lZK4tq5OlzE4pzmlqg+WC1OSG2dFAvLcs8ycRtXYqQb5eskPH1eNXS7k5GPnMqqxTUn32nxkaFBce3JAXmtlhLlqVjih2w+TTXPEtbU18ty4gPB5kyMgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIAT0zaKZ3BgwBTzsviRA2/JY2dGM1nVfOSy8vpETB5pYpWK8iiRkfSAauxIUB7HkqqrVY0dUy7nsGKdD4/K14l1Mi2PWBkcHlWNHYnFxLXD7fJIEyvdl1TVm4J8HdYndA/r1hb5vNQk5OvEam5uEtcWhvtUY8fi8nkpl+SxSlamoIuEyublcTmFkm7skVH5tg+VdccUiYYWcW2sJiquLZUrojqOgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABOTNssuLfeesskEjWi2tKb+8TjHj3So5qP9OCguDYUDKjGzo4Mi2v7jh9TjR1VZMG1zWlUjV1Tk1DVZ3LyfLd80VONXVKUlz3d9gkrsuBqa3XrJGhkWVljyjl5jt3cdt32vOZjl4hrW5t0GXbBoPw1bk2NLpMwURMX14Yiugy7SES3PUNx+XqJJhtUYyeb5I+foifPxbQam+RZfQHFOgwFZa2FIyAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBPTNoqnv7/fxOOy+JHhYXlUxeFD76rmY3AwLa4Nh3RRL5nhIXFteqBPNXYyJo/kCClfhjRWdDEy4WhEXNvUVKcaO1GrqA/oYkpKis1ZKsujj6z0QL+qfmR4RFzbUKeLnSmW5PNeKJZUY49m5Y/NTK6oGjsRl+9XhYpu29clU6r6pqQ8imeOp3vAjYzmFbUF1djxWvl8lxXHK8GQbNtwBAQAcELVgLq7u821115r6urqTGtrq7nlllvMvn0Tg0BzuZxZs2aNaW5uNslk0qxatcr09vZO9nwDAGZTA9q+fbvfXHbt2mVefPFFUywWzfLly00mkxmvefDBB83zzz9vnnnmGb/+6NGj5tZbb52KeQcAzJZzQFu2bJlwe+PGjf6R0J49e8z1119v0um0+cEPfmCeeuopc8MNN/g1Tz75pLn88sv9pvXJT35ycuceADBjndU5INtwrKbff6eEbUT2qGjZsmXjNZdddpmZN2+e2blz5ynHyOfzZmhoaMIEAKh+Z9yAKpWKeeCBB8x1111nrrrqKv93PT09JhqNmoaGiV+41NbW5t93uvNKqVRqfJo7d+6ZzhIAYDY0IHsu6PXXXzebNm06qxlYt26dfyQ1Nh0+fPisxgMAVPHngO677z7zwgsvmB07dpiurq7x37e3t5tCoWAGBwcnHAXZq+DsfacSi8X8CQAwu6iOgDzP85vP5s2bzcsvv2zmz58/4f5rrrnGRCIRs3Xr1vHf2cu0Dx06ZJYsWTJ5cw0AmF1HQPZtN3uF23PPPed/FmjsvI49d5NIJPyfd955p1m7dq1/YUJ9fb25//77/ebDFXAAgDNuQBs2bPB/Ll26dMLv7aXWd9xxh//vb3/72yYYDPofQLVXuK1YscJ8//vf1/wZAMAsENa+BfdR4vG4Wb9+vT+djWg05k8SoZA8nyoY0mVC2WY6FbVWLC4/9/X+Kws/SmOqVlzbdf4fzuNJdHa2qerntM4R19pL9jXqG5rFtfmSLsMuV5LvVxVPN/aJ46e+KvR0+nqOimsbk1HV2M2t8u2ZG5VnI1rvHJGnoBw++LZq7Ia6GnHtySFZruSY9qHslO3jiVr5Y9MaVWTkZZV5el5Yvo8HhPluVrH00b3CIgsOAOAEDQgA4AQNCADgBA0IAOAEDQgA4AQNCADgBA0IAOAEDQgA4AQNCADgBA0IADBzvo7hXAh4AX+Sfjme1OioLpLj5MCAuLZclsda+PXFgri2VMirxs7n5MsZi+miW7yALs4oFJZHDjU151Rjl438G3SP9w2qxh7OyeNYIlF5TImVGRlW1Q8Ojohri1nd68pgUBabYp3oOaIa+5Xdr4lrD799UDV2ska+37bO+d23Nks1NtSp6hsa6sW1KWWsVjAof7wFFLXaGKZkvXwZR0dljx2OgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABOTNssuEq55E8S+aw8s2s4nVbNx8mT8iy4SqmoGturlMW1xbwuCy4jj0gzuawuf+34iZOq+pOD8tyzXmVeWy4vz9974zf7VWMf7+sT1yZqEqqxPU++7a2RtHydNzfUqsa+5OILxLXFgi5L8e1j8vlOZ+WZjv68BOQZdtke3X7128O9qnrPyOc9FpVnI1rxRNxI1dXJ89qsC+bLMwZb21vFtbmc7PmKIyAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBM0IACAEzQgAIATNCAAgBPTNoonHk+YREIWb1JfJ48eaZ3TrJqPUCAgrk3EoqqxEzXyiI1yURfzI40xsuJxXTSINu6js6tDXFubrFONfejIMXFtf78ujuXAbw+Ja8PhkGrsYqmgqh8alEfazGlJqcaOxuUxQo1Num3f2NYlrm1oaVeNHY/KXz8XcroIod5j8v3KGhjoF9fm8/Jay5MnDpnmZt3zmwnLnzvLAfnzWz4v2785AgIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4MW2z4JI1NguuRlRbLpbF43a2tanmo6WhUVw7p0WXw9TQIM/V8ryKauxySZMFJ8+ks+pTuqyxtg75Og+FI6qxw1F5jtnhIz2qsbP5vLg2FNY9lHL5rKq+UpFv/4ryYZ3JyfeVlHLsZKpJXBswitAzY0wsKs/fK+Z063skK18n1tCoPKsxk9c9lnO5nLg2PKLLGEyPyPfxxlH52IUCWXAAgGlM1YC6u7vNtddea+rq6kxra6u55ZZbzL59+ybULF261AQCgQnTPffcM9nzDQCYTQ1o+/btZs2aNWbXrl3mxRdfNMVi0SxfvtxkMpkJdXfddZc5duzY+PTYY49N9nwDAGY41Ru6W7ZsmXB748aN/pHQnj17zPXXXz/++5qaGtPervtuDwDA7HJW54DS6bT/s6lp4onGH/3oR6alpcVcddVVZt26dWZ09PRfBpXP583Q0NCECQBQ/c74Kjh7Vc4DDzxgrrvuOr/RjPnCF75gzj//fNPZ2WleffVV85WvfMU/T/TTn/70tOeVHnnkkTOdDQDAbGtA9lzQ66+/bn79619P+P3dd989/u+rr77adHR0mBtvvNEcOHDAXHjhhR8Yxx4hrV27dvy2PQKaO3fumc4WAKCaG9B9991nXnjhBbNjxw7T1fXh3/m+ePFi/+f+/ftP2YBisZg/AQBmF1UD8jzP3H///Wbz5s1m27ZtZv78+R/5f/bu3ev/tEdCAACcUQOyb7s99dRT5rnnnvM/C9TT87tPlqdSKZNIJPy32ez9f/qnf2qam5v9c0APPvigf4XcwoULNX8KAFDlVA1ow4YN4x82fa8nn3zS3HHHHSYajZqXXnrJPP744/5ng+y5nFWrVpmvfvWrkzvXAIDZ9xbch7ENx35YdTIUcgUTCsiyngo5eZ5RPqvLhJJmGlk55dgjIflV8Nns6S9lP5V8Vr5OEjXyPDWrXFFmdinO8RXK8lw/6+jRY+LakydPqsa2KR5S9fVJ1di1FVnO4ZhsVp4HVizq8sByBXnu2XBGPh9WRLGPB4O6/cq+4JVKJOW5i1ZLqy6vrVSW7ysmKJ9vKxiSfzQlEtPtVyYYm5KMwYqRrT+y4AAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAATtCAAABO0IAAAE7QgAAAM+v7gKZaPj9qggFZNEd2NCMeN6eMtBn71leJkWHdt7lGIhFx7ZBiPqysIoonWaeLkelMD6rqh4YU63BUF/Xy2qtviGvf/u1B1dheUP76bE5rs2rs+hpdZEqpVBTX5nK6SKhoVBHHUlFG1CjqwyFFnI1Pvn1iyoiaVIPutXk+L98+hZJuHXoB+bzEFdvSisbi4tpIRLGfeLJtyREQAMAJGhAAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwIlpmwVXE4+ZREKWPeSVa8XjFrIp1XwEjTy3qVSU50FZgYB87FrhuhiTqq8T17a2tarGnnf+XFV9Y2OTuLavf0A19rtNDeLaZkWtLyjPJmtRjt3QqKuviUfFtekhXSZhpVyasn08m5dn+3nKnLlcTj52Jil/jrACRpZDOaZQkK/DSkU3tifMVfsdbZ6eYmRFJl0gQBYcAGAaowEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcmLZRPPV1daampkZUW5dMiseNRUKq+UgqInBGRzOqsY0nj+QIhXSbKtUgj3o5r6tLNfb5F5yvqq+tk2+fI0eOqsYeGOgX1w4P6yJqhjOj4tqQIrLJqhQLqnqvJK8vZHX74YhivYxm5evEGh4eFtcWCrp1kojHpiSayqpJxFX1nuKxXCmVVWPHovLlrK3VRQ7F4wlxbSgof+4MBWS1HAEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnKABAQCcoAEBAJygAQEAnJi2WXCVctFUSkVZbUWerVRSZGpZ2Zw8+2poKK0au1KWz3ckHFGNHQjIs6kS8ahq7HA4oKuPyOf9yLvHVGO/e/iwuPbE8R7V2INpeUba4Mk+1djxhDyDy8rlc+LakZER1dhDQ0NTlneYy+fFtcGg7vVwwJPn79Uqs92CtbIcyjPJjtPm0oUVj/065dgtzY3ysevkY0ejsucUjoAAAE6oGtCGDRvMwoULTX19vT8tWbLE/PznPx+/P5fLmTVr1pjm5maTTCbNqlWrTG9v71TMNwBgNjWgrq4u8+ijj5o9e/aY3bt3mxtuuMHcfPPN5o033vDvf/DBB83zzz9vnnnmGbN9+3Zz9OhRc+utt07VvAMAZss5oJtuumnC7X/6p3/yj4p27drlN6cf/OAH5qmnnvIbk/Xkk0+ayy+/3L//k5/85OTOOQBgRjvjc0Dlctls2rTJZDIZ/604e1RULBbNsmXLxmsuu+wyM2/ePLNz587TjpPP5/2ToO+dAADVT92AXnvtNf/8TiwWM/fcc4/ZvHmzueKKK0xPT49/5UPD+76Js62tzb/vdLq7u00qlRqf5s6de2ZLAgCo7gZ06aWXmr1795pXXnnF3HvvvWb16tXmzTffPOMZWLdunUmn0+PTYcVltQCAWfQ5IHuUc9FFF/n/vuaaa8x///d/m+985zvmtttu87/TfXBwcMJRkL0Krr29/bTj2SMpOwEAZpez/hxQpVLxz+PYZhSJRMzWrVvH79u3b585dOiQf44IAIAzPgKyb5etXLnSv7BgeHjYv+Jt27Zt5he/+IV//ubOO+80a9euNU1NTf7nhO6//36/+XAFHADgrBrQ8ePHzZ//+Z+bY8eO+Q3HfijVNp8/+ZM/8e//9re/7cdp2A+g2qOiFStWmO9///vmTPT1HTeJuCyuJJuVx5ScHBhQzUdv73FxbX9/v2rsfE4eU6KleVuzsSGlGjtZX6+qr8hTgUxfv277HDz4jrj26IdcDHMq+YIsCkoTPTImFtdFwxhF+pEmmsoqK+KpQroUJlObkO+HCWVcTr0idqaxUbfPNjbqHhP1SU1MjS5WK6KIsopr16EiXieh2JaB4BQ0IPs5nw8Tj8fN+vXr/QkAgA9DFhwAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAMAJGhAAwAkaEADACRoQAGBmpGFPNc/7XW5LLieP18kpIm1sRJCGTfiWsl/Ip1EslcxUCYbkry0KRfkyWnnFOrF+v0mnZB2WyiVVcK6Gpl4/dnnaRPFM5XJOaYRQWV5fUj7WtPuh5nnCGO+MnhMlAkFdVlJeESEVCMjnI/f759mPmveAp1m6c+DIkSN8KR0AVAH7/W5dXV0zpwHZV1hHjx41dXV1JhD4Qze3X9VtG5NdIJu0Xa1YzuoxG5bRYjmry9AkLKdtK/YbEzo7O/2A6hnzFpyd2Q/rmHaFVPPGH8NyVo/ZsIwWy1ld6s9yOe03JnwULkIAADhBAwIAODFjGpD9grWHH35Y9UVrMxHLWT1mwzJaLGd1iZ3D5Zx2FyEAAGaHGXMEBACoLjQgAIATNCAAgBM0IACAEzOmAa1fv95ccMEFJh6Pm8WLF5v/+q//MtXk61//up/88N7psssuMzPZjh07zE033eR/Gtouz7PPPjvhfnv9y0MPPWQ6OjpMIpEwy5YtM2+99ZaptuW84447PrBtP/vZz5qZpLu721x77bV+Qklra6u55ZZbzL59+ybU2PzGNWvWmObmZpNMJs2qVatMb2+vqbblXLp06Qe25z333GNmkg0bNpiFCxeOf9h0yZIl5uc///k535YzogH9+Mc/NmvXrvUvDfyf//kfs2jRIrNixQpz/PhxU02uvPJKc+zYsfHp17/+tZnJMpmMv63si4dTeeyxx8x3v/td88QTT5hXXnnF1NbW+ttVE0Q7E5bTsg3nvdv26aefNjPJ9u3b/SekXbt2mRdffNEP61y+fLm/7GMefPBB8/zzz5tnnnnGr7eRWrfeequptuW07rrrrgnb0+7LM0lXV5d59NFHzZ49e8zu3bvNDTfcYG6++WbzxhtvnNtt6c0An/jEJ7w1a9aM3y6Xy15nZ6fX3d3tVYuHH37YW7RokVet7K62efPm8duVSsVrb2/3vvnNb47/bnBw0IvFYt7TTz/tVctyWqtXr/Zuvvlmr5ocP37cX9bt27ePb7tIJOI988wz4zX/93//59fs3LnTq5bltP74j//Y++u//muv2jQ2Nnr/8i//ck635bQ/ArIx57ZL27dn3psXZ2/v3LnTVBP79pN9G2fBggXmi1/8ojl06JCpVgcPHjQ9PT0TtqvNjrJvr1bbdrW2bdvmv6Vz6aWXmnvvvdf09/ebmSydTvs/m5qa/J/2MWqPFt67Pe1byPPmzZvR2/P9yznmRz/6kWlpaTFXXXWVWbdunRkdHTUzVblcNps2bfKP8uxbcedyW067MNL36+vr81dQW1vbhN/b27/5zW9MtbBPvBs3bvSfoOwh/SOPPGI+/elPm9dff91/P7ra2OZjnWq7jt1XLezbb/bti/nz55sDBw6Yv//7vzcrV670H8yhUMjMNDax/oEHHjDXXXed/wRs2W0WjUZNQ0ND1WzPUy2n9YUvfMGcf/75/ovFV1991XzlK1/xzxP99Kc/NTPJa6+95jcc+5a3Pc+zefNmc8UVV5i9e/ees2057RvQbGGfkMbYk4O2Idmd/Cc/+Ym58847nc4bzs7tt98+/u+rr77a374XXnihf1R04403mpnGniOxL4xm+jnKM13Ou+++e8L2tBfR2O1oX1zY7TpTXHrppX6zsUd5//7v/25Wr17tn+85l6b9W3D2MNe+Snz/FRj2dnt7u6lW9tXHJZdcYvbv32+q0di2m23b1bJvsdr9eiZu2/vuu8+88MIL5le/+tWEr02x28y+XT44OFgV2/N0y3kq9sWiNdO2ZzQaNRdddJG55ppr/Kv/7IU03/nOd87ptgzOhJVkV9DWrVsnHBrb2/bwsVqNjIz4r6jsq6tqZN+Osjvze7er/SIsezVcNW/XsW/9teeAZtK2tddX2Cdl+zbNyy+/7G+/97KP0UgkMmF72rel7HnMmbQ9P2o5T8UeRVgzaXuein1ezefz53ZbejPApk2b/KujNm7c6L355pve3Xff7TU0NHg9PT1etfibv/kbb9u2bd7Bgwe9//iP//CWLVvmtbS0+FfhzFTDw8Pe//7v//qT3dW+9a1v+f9+5513/PsfffRRfzs+99xz3quvvupfKTZ//nwvm8161bKc9r4vfelL/tVDdtu+9NJL3sc//nHv4osv9nK5nDdT3HvvvV4qlfL30WPHjo1Po6Oj4zX33HOPN2/ePO/ll1/2du/e7S1ZssSfZpKPWs79+/d73/jGN/zls9vT7rsLFizwrr/+em8m+bu/+zv/yj67DPaxZ28HAgHvl7/85TndljOiAVnf+973/BUSjUb9y7J37drlVZPbbrvN6+jo8JfvvPPO82/bnX0m+9WvfuU/Ib9/spclj12K/bWvfc1ra2vzX2DceOON3r59+7xqWk77xLV8+XJvzpw5/qWt559/vnfXXXfNuBdPp1o+Oz355JPjNfaFw1/91V/5l/PW1NR4n/vc5/wn72pazkOHDvnNpqmpyd9nL7roIu9v//ZvvXQ67c0kf/mXf+nvi/b5xu6b9rE31nzO5bbk6xgAAE5M+3NAAIDqRAMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAOEEDAgA4QQMCADhBAwIAGBf+PyCi+yCdPllVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "U, sigma, V = prepare_dataset(200)\n",
    "print(f\"U shape: {U.shape}, sigma shape: {sigma.shape}, V shape: {V.shape}\")\n",
    "\n",
    "reconstructed_img = reconstruct_img(U[1], sigma, V)\n",
    "\n",
    "reconstructed_img = reconstructed_img.flatten()\n",
    "U_test = (reconstructed_img @ torch.inverse(V)) @ torch.inverse(torch.diag(sigma))\n",
    "new_img = U_test @ torch.diag(sigma) @ V\n",
    "new_img = new_img.reshape(3, 32, 32)\n",
    "new_img = new_img.permute(1, 2, 0)\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbf5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_loader): \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_test_tensor, y_test_tensor in test_loader:\n",
    "            y_test_tensor = y_test_tensor.flatten()\n",
    "            outputs = model(X_test_tensor)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == y_test_tensor).sum().item()  # Accumulate correct predictions\n",
    "            total += y_test_tensor.size(0)  # Accumulate total samples\n",
    "\n",
    "\n",
    "    accuracy = 100. * correct / total  # Calculate overall accuracy\n",
    "    # print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d638566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, epochs, criterion, experiment_name = None): \n",
    "    train_accuracy = [] \n",
    "    val_accuracy = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0 \n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        val_acc = validate(model, test_loader)\n",
    "        val_accuracy.append(val_acc)\n",
    "\n",
    "        train_accuracy.append(correct / total)\n",
    "        # print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {correct / total:.2f}%\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}, Validation Accuracy: {val_acc}%\")\n",
    "\n",
    "    # Save the model\n",
    "    if experiment_name is not None:\n",
    "        torch.save(model.state_dict(), f\"./results/cifar-model/{experiment_name}.pth\")\n",
    "        print(f\"Model saved as {experiment_name}.pth\")\n",
    "    else: \n",
    "        torch.save(model.state_dict(), f\"./results/cifar-model/{experiment_name}.pth\")\n",
    "        print(f\"Model saved as {experiment_name}.pth\")\n",
    "\n",
    "    return max(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab0d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/mbg8sv_n2cz_7gw8tbfw1tvm0000gn/T/ipykernel_9138/2846711636.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = TensorDataset(torch.tensor(U, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U shape: torch.Size([50000, 200]), sigma shape: torch.Size([3072]), V shape: torch.Size([3072, 3072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m     31\u001b[39m experiment_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m acc = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m accuracies.append(acc)\n\u001b[32m     35\u001b[39m singular_values.append(k)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, epochs, criterion, experiment_name)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     13\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     labels = labels.squeeze()\n\u001b[32m     16\u001b[39m     loss = criterion(outputs, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/image-distillation/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/image-distillation/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cornellSP2025/cs6386-main/distilled-image-dataset/model.py:37\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.reconstruct_img(x)\n\u001b[32m     36\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.conv1(x))\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m x = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m     39\u001b[39m x = F.max_pool2d(x, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/image-distillation/lib/python3.11/site-packages/torch/_jit_internal.py:622\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/image-distillation/lib/python3.11/site-packages/torch/nn/functional.py:830\u001b[39m, in \u001b[36m_max_pool2d\u001b[39m\u001b[34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    829\u001b[39m     stride = torch.jit.annotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data = np.load('./CompressedDatasets/cifar/dataset.npz')\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "singular_values = [] \n",
    "accuracies = [] \n",
    "\n",
    "for k in range(200, 3072, 200):  \n",
    "    U, sigma, V = prepare_dataset(k)\n",
    "    print(f\"U shape: {U.shape}, sigma shape: {sigma.shape}, V shape: {V.shape}\")\n",
    "    \n",
    "    # Define training parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleCNN(sigma, V).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(torch.tensor(U, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test, torch.tensor(y_test, dtype=torch.long))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Train the model\n",
    "    experiment_name = f\"model_{k}\"\n",
    "    acc = train(model, train_loader, test_loader, optimizer, epochs, criterion, experiment_name)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    singular_values.append(k)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5002b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c8cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-distillation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
